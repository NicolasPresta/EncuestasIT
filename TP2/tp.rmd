---
title: "TP2-IA-RNA"
output: github_document
---

```{r setup, include=FALSE}

# --- Include de Librerias --- 
library(knitr)
library(lattice)
library(ggplot2)
library(caret)
library(nnet)
library(neuralnet)
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')

knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)


```

## TP 2 - Inteligencia Artificial - UTN FRBA


### Resumen:
En el presente trabajo se buscará desarrollar una tecnica de la inteligencia artificial para resolver la siguiente tarea: "Predecir el salario neto por hora de un empleado del sector tecnologico en Argentina en base a las caracteristicas del empleo y su desarrollo profesional". 
Para esta tarea se implementará una red neuronal artificial donde el output será una aproximación al salario.

### Introducción:
El mercado laboral del sector tecnologico argentino tiene caracteristicas muy particulares y resulta de especial interes, sobre todo para trabajadores y empleadores del sector, tener una vision más certera de como se mueve el mercado laboral. 
Una de las caracteristicas de mayor interes es el salario de los empleados. 
Para relevar esta información de mano directa de los empleados se creo la plataforma www.encuestasit.com, donde se encuesta a los empleados sobre las caracteristicas de su trabajo, su desarrollo profesional y su salario. Esta encuesta se realiza anualmente y luego se publican los resultados en el sitio. Ademas se suben los datos en crudo en formato csv.
Para este trabajo solo se utilizarán datos del 2016.
El objetivo es aproximar el salario neto por hora de un empleado en función de las caracteristicas del trabajo y del trabajador.


### Elementos del Trabajo y Metodología:

- Modelo de RNA utilizada con la justificación de su elección.
Se utilizará el modelo Backpropagation ya que es el que mejor se ajusta a la tareas de aproximación y clasificación. 

- Arquitectura y topología final de la RNA.
En principio una sola capa oculta de 20 neuronas. Esta limitación en el modelo corresponde más a limitaciones de infraestructura hardware necesaria para entrenar el modelo que a un ajuste que busque minimizar el error de la aproximación

TODO 

- Descripción de los patrones utilizados para el entrenamiento y la validación de la RNA (por lo menos se debe utilizar un 25% de los patrones disponibles para la validación).
Se separa el dataset en 2 sub conjuntos: un conjunto de entrenamiento que contiene el 80% de los casos, elegidos aleatoreamente, que se utilizará para el entrenamiento. Y otro subconjunto de validación con el 20% de los casos restantes.


- Herramientas, lenguajes y/o librerías seleccionadas para la implementación de la RNA.
Se implementara en R, utilizando la libreria TODO

- En caso de haber utilizado varios prototipos, las características de las principales versiones utilizadas.

### Resultados:

- El error general obtenido en el entrenamiento de la RNA.

- Los resultados obtenidos al aplicar en la RNA entrenada los patrones de validación (correctos y/o incorrectos). Para ello, se debe utilizar una tabla que indique por cada patrón:
  - los datos de entrada ingresados,
  - la salida generada por la RNA,
  - la salida esperada para los datos de entrada, y 
  - la comparación entre la salida esperada y la generada.

### Discusión:
Análisis de los resultados obtenidos en la sección anterior. Para ello, se puede
evaluar de los resultados según dos perspectivas:
 - ¿El Sistema Inteligente propuesto resuelve satisfactoriamente el problema? En el caso en que el resultado no fuese satisfactorio, indique posibles causas y proponga cursos de acción.
 - ¿Cómo se compara con otras arquitecturas?


### Conclusión:
 - Conclusiones de la implementación del Sistema Inteligente.
 - Relación entre los resultados, el modelo utilizado y la teoría vista en clase.
 - Descripción de los problemas encontrados durante la implementación (si hubo alguno) y las estrategias de resolución aplicadas.


### Referencias:
 - Cita de bibliografía consultada, tanto escrita como digital (tal como una página web).  
    - http://www.kdnuggets.com/2016/08/begineers-guide-neural-networks-r.html/2
    - https://www.r-bloggers.com/fitting-a-neural-network-in-r-neuralnet-package/

 - Cita de otras fuentes teóricas, datos, técnicas y cualquier otra cosa que se haya utilizado para la realización del trabajo práctico.
    - Aplicación de algunos conceptos del curso https://www.coursera.org/learn/machine-learning
 
 
***

### Carga de los datos  

```{r cargar datos}
# ----------------------  Levantar DataFrame  ----------------------

# Levantamos el archivo ya formateado,
encuestas <- read.csv("./datos.csv")
encuestas$X <- NULL

```

### Resumen de datos

Visualizamos un resumen de los datos que vamos a usar para esta clasificación.

```{r resumen de datos}
# ----------------------  imprimir resumen de campos  ----------------------

str(encuestas)

summary(encuestas)

# ----------------------   primeros campos  ---------------------- 
kable(head(encuestas))

```

### Preprocesado de datos  

- Borramos caracteristicas que estan demasiado vinculadas a lo que vamos a predecir  
- Separamos la columna a predecir (SalarioNetoPorHora)   
- Todos las columnas de tipo "Factor" (Enumeración) las llevamos a int (entero)  
- Los valores faltantes (NA) los ponemos en 0  
 
```{r Preprocesado de datos}

# Borramos caracteristicas que estan demasiado vinculadas a lo que vamos a predecir
# No las vamos a utilizar ya que queremos poder predecir el salario en base a
# otras caracteristicas del empleo
encuestas$SalarioActualNeto <- NULL
encuestas$SalarioIdealNeto <- NULL
encuestas$DiferenciaSalarioRealIdeal <- NULL
encuestas$RangoSalario <- NULL

# Convercion de Enums a Int
encuestas$IdSexo <- as.numeric(encuestas$IdSexo)
encuestas$IdNivelEducativo <- as.numeric(encuestas$IdNivelEducativo)
encuestas$IdTipoDeEmpresa <- as.numeric(encuestas$IdTipoDeEmpresa)
encuestas$IdProvincia <- as.numeric(encuestas$IdProvincia)
encuestas$IdPuesto <- as.numeric(encuestas$IdPuesto)
encuestas$TrabajaDesdeCasa <- as.numeric(encuestas$TrabajaDesdeCasa)
encuestas$LeGustaTrabajarDesdeCasa <- as.numeric(encuestas$LeGustaTrabajarDesdeCasa)
encuestas$CambioPorMejorSalario <- as.numeric(encuestas$CambioPorMejorSalario)
encuestas$CambioPorMejorAmbiente <- as.numeric(encuestas$CambioPorMejorAmbiente)
encuestas$CambioPorFormaDeTrabajo <- as.numeric(encuestas$CambioPorFormaDeTrabajo)
encuestas$CambioPorTecnologia <- as.numeric(encuestas$CambioPorTecnologia)
encuestas$NoCambio <- as.numeric(encuestas$NoCambio)
encuestas$NivelDeDesconfianza <- as.numeric(encuestas$NivelDeDesconfianza)
encuestas$CambioPorCercania <- as.numeric(encuestas$CambioPorCercania)
encuestas$CambioPorMenorCargaHoraria <- as.numeric(encuestas$CambioPorMenorCargaHoraria)
encuestas$CambioPorOportunidadDeCarrera <- as.numeric(encuestas$CambioPorOportunidadDeCarrera)
encuestas$TienePersonasACargo <- as.numeric(encuestas$TienePersonasACargo)
encuestas$RelaciónLaboral <- as.numeric(encuestas$RelaciónLaboral)
encuestas$RangoHora <- as.numeric(encuestas$RangoHora)
encuestas$CargaLaboral <- as.numeric(encuestas$CargaLaboral)
encuestas$Antiguedad <- as.numeric(encuestas$Antiguedad)
encuestas$Experiencia <- as.numeric(encuestas$Experiencia)
encuestas$RangoEdad <- as.numeric(encuestas$RangoEdad)
encuestas$IdTecnologiaPrincipal <- as.numeric(encuestas$IdTecnologiaPrincipal)
encuestas$CargaLaboral <- as.numeric(encuestas$CargaLaboral)
encuestas$Semestre <- as.numeric(encuestas$Semestre)

# Los valores faltantes (NA) los ponemos en 0
encuestas[is.na(encuestas$CantidadDeMesesParaCambiarDeTrabajo),]$CantidadDeMesesParaCambiarDeTrabajo <- 0
encuestas[is.na(encuestas$RelaciónLaboral),]$RelaciónLaboral <- 0
encuestas[is.na(encuestas$RangoHora),]$RangoHora <- 0
encuestas[is.na(encuestas$Experiencia),]$Experiencia <- 0
encuestas[is.na(encuestas$Antiguedad),]$Antiguedad <- 0

# Escalado entre 0 y 1
range01 <- function(x){(x-min(x))/(max(x)-min(x))}
encuestas <- as.data.frame(sapply(encuestas, range01)) 

# Output
Output <- encuestas$SalarioNetoPorHora
encuestas$SalarioNetoPorHora <- NULL

```

### Separación en sets

Selección de una submuestra del 80% para entrenamiento y 20% para test.

```{r separación en sets}

set.seed(101)
indices <- sample(1:nrow(encuestas),size=round(0.2*nrow(encuestas)))

entrenamiento_input <- encuestas[-indices,]
entrenamiento_output = Output[-indices]
entrenamiento <- entrenamiento_input
entrenamiento$Output <- entrenamiento_output

test_input <- encuestas[indices,]
test_output <- Output[indices]

```

### Armado de la red neuronal

```{r armado del modelo}

# Outputs:
nombres <- names(encuestas)

# Inputs:
f <- paste(nombres,collapse=' + ')
f <- paste('Output ~',f)

# Formula (Output en función de los inputs):
f <- as.formula(f)

# -------------------


# Creación y entrenamiento de la red neuronal

nn <- neuralnet(formula = f,                
                data = entrenamiento,                
                hidden=c(20),                
                linear.output=TRUE,
                stepmax = 50000)

# nn2 <- nnet(entrenamiento_input, entrenamiento_output, data=dat.in, size=20,maxit=10000, decay=0.001,            reltol=FALSE)

```
### Evaluación del modelo

```{r evaluación del modelo}

# Calculamos las predicciones usando el modelo
predicciones <- compute(nn,test_input)
# predicciones <- predict(nn2, test_input)

# Redondiamos la salida del modelo (si es > 0.5 lo consideramos 1)
# predicciones <- sapply(predicciones$net.result,round,digits=0)
# predicciones <- sapply(predicciones,round,digits=0)

# Validamos las predicciones con los valores reales.
# table(test_output,predicciones)

```

### Visualización del modelo

```{r  Visualización del modelo}

plot(nn)
# plot.nnet(nn2)

```
